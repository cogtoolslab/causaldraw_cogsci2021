# Using visual representations of physical mechanism to identify objects

**Researchers**: Holly Huey, Caren Walker, and Judith Fan

## Study information
**Title**: 
causaldraw_identification

### Research questions
Causal knowledge allows us to make predictions about future events and act upon objects in order to generate desired outcomes[1-2]. Huey, Walker, and Fan (2020) collected a dataset of 300
sketches to explore visual communication as a means to convey causal knowledge to others in a condensed, exportable format. This study capitalized on prior work that has examined how the spatial layout of elements in well-designed visualizations, such as sketches, mirrors the placement and relations of elements in the physical world, making it easier to grasp the correspondence among elements in each domain[3-6]. Visualizations have also been shown to promote inference of abstract relations by leveraging a small set of relational symbols, such as lines and arrows[7-8]. 

In the original study, participants drew simple machines (gears, levers, and pulleys), which comprise a unique class of objects that can be rich in both visual appearance and causal information. They were prompted to generate visual explanations (e.g., of how a machine functions) or visual depictions (e.g., of what a machine looks like). Results demonstrated that, while participants tended to devote an approximately equal amount of ink and equal number of strokes between conditions, they drew a higher proportion of causally relevant elements in visual explanations than visual depictions (P<.001). Participants also employed more symbols and drew less background elements in their visual explanations (P<.001, respectively). Here we use “background” to describe the elements that were not did not contribute to the machines’ function. 

However, a critical aspect of understanding visual communication involves not only understanding how we produce visual representations but also how we use them in order to identify objects or intervene on them to generate desired outcomes. The current study will therefore explore which visual properties of the collected sketches facilitate accurate object recognition. The study will present a new group of participants with the sketches generated by the original study, as well as an array of the original objects that the sketches were intended to represent. By measuring whether participants can accurately identify which object the sketch represents and duration of their response time, the study aims to analyze which properties of sketches, such as which elements were drawn and level of detail, differentially facilitate participant’s object recognition between conditions. 


### Hypotheses
If  participants of the original study (Huey, Walker, & Fan, 2020) were more selective when producing informative visual explanations than when producing faithful visual depictions, we hypothesize that visual explanations will contain more causally relevant information. Conversely, however, this may mean that visual explanations contain less visual information that contributes to accuracy object recognition as opposed to visual depictions. Specifically: 

We predict visual depictions will facilitate more accurate identification of which target machine the sketch represents than visual explanations. 

We predict visual depictions will facilitate shorter response times than visual explanations. 

Within visual depictions, we predict sketches that include more detail, measured by the number of strokes and amount of “ink”, will facilitate more accurate and faster identification of target machines. Here, the amount of “ink” is measured by the arc length of the mark made between the depression of the mouse cursor (“pen down”) and the lifting of the mouse cursor (“pen up”).

Within visual explanations, we predict sketches that include more symbols will lead to less accurate performance and higher response times, whereas sketches that include more background elements will lead to more accurate performance and lower response times. 


## Design Plan
###   Study type
Experiment - A researcher randomly assigns treatments to study subjects, this includes field or lab experiments. This is also known as an intervention experiment and includes randomized controlled trials

### Blinding
For studies that involve human subjects, they will not know the treatment group to which they have been assigned. 

Is there any additional blinding in this study?
No response

###   Study design
Participants will identify which machine each sketch represents on a custom web-based platform. Each machine will consist of a unique spatial configuration of brightly colored mechanical elements, including gears, pulleys, and lever, that can be used to activate a light bulb. Half of these mechanical elements can be manipulated to activate the light (causal), whereas the other half of them cannot (non-causal). For each machine, these causal and non-causal elements will be equated in size, number, and type (gears, levers, and pulleys) to ensure that they are matched in perceptual salience. Machines will also vary by two levels of complexity. 

During test trials, participants will click on a crosshair in the middle of their screen. Upon clicking, a sketch will appear in the location of the crosshair with a circular array of target machines surrounding the sketch. Each machine will be equidistant from the sketch and each other. The location of machines will be randomized across trials. Participants will be instructed to click on the machine that the sketch represents as accurately and quickly as they can. Participants will be told that they should try to make a response in under 5 seconds. Upon making a response, they will receive feedback on whether or not they clicked on the correct target machine and how quickly they made their response. If participants do not make a response in 10 seconds, they will see a message reminding them to try to make their response in under 5 seconds, and the trial will be skipped.

Participants will complete 300 trials so that each participant will make judgments about the entire dataset of sketches. The 300 trials will be split into blocks of 50 trials between which participants can momentarily rest if they desire. Each block will contain an approximately equal number of visual depictions and visual depictions and within condition, an approximately equal number of sketches representing gears, levers, and pulleys of both complexity levels. 

## Sampling Plan
### Existing Data
Registration following analysis of the data: As of the date of submission, you have accessed and analyzed some of the data relevant to the research plan. This includes preliminary analysis of variables, calculation of descriptive statistics, and observation of data distributions. Please see cos.io/prereg for more information. 

##   Data collection procedures
We plan to include 50 English-speaking adults. Participants will be recruited from the University of California, San Diego study pool through SONA and will receive 1 credit for their participants in our ~60 minute study. 

##   Sample size
We plan to include 50 English-speaking adults who did not participate in the original study. 

### Sample size rationale
Because this is an exploratory study, we do not yet have reliable estimates of effect size. Our sample size was therefore chosen in order to obtain enough data to get initial estimates of effect size, as well as estimates of individual and item-level variation. This sample size rationale was also guided by a similar sample size of the original study (Huey, Walker, & Fan, 2020)

### Stopping rule
Data collection will stop when 50 participants have successfully completed the study. 

## Variables
### Measured variables
We will analyze the effect of condition on two outcome variables: accuracy and response time.

## Analysis Plan
### Statistical Models
Below are how we plan to specify each measured variable corresponding to the statistical model: 

Null model: Response time (RT)

First, we will attempt to fit the “maximal” versions of each model, including both random slopes and intercepts for participants (i.e., `gameID`), items (i.e., `toy_type`), and sketch (i.e., `sketchID`) 

m0 <- lmer(log(final_data$rt) ~ 1 + (1|toy_type) + (1|sketchID) + (1|gameID) + (totalStrokes|condition) + (totalStrokes|toy_type), data=final_data, REML=FALSE)

If the model fails to converge, we will remove the random intercept of toy_type and use the following model: 

m0 <- lmer(log(final_data$rt) ~ 1 + (1|sketchID) + (1|gameID) + (totalStrokes|condition) + (totalStrokes|toy_type), data=final_data, REML=FALSE)

Null model: Accuracy (corrAns)

Because corrAns is binary (0 = incorrect, 1 = correct), we are using a glmer model: 

m1 <- glmer(final_data$corrAns ~ 1 + (1|toy_type) + (1|sketchID) + (1|gameID) + (totalStrokes|condition) + (totalStrokes|toy_type), family="binomial", data=final_data)

If the model fails to converge, we will remove the random intercept of toy_type and sketchID, as well as interaction terms: 

m1 <- glmer(final_data$corrAns ~ 1 + (1|sketchID) + (1|gameID) + (totalStrokes|condition) + (totalStrokes|toy_type), family="binomial", data=final_data)

Does condition influence response time (RT)? 

m_RT <- lmer(log(final_data$rt) ~ condition + condition*numCausal + condition*numFunctional + condition*numSymbol + condition*numBackground + (1|toy_type) + (1|sketchID) + (1|gameID) + (totalStrokes|condition) + (totalStrokes|toy_type), data=final_data, REML=FALSE)

If the model fails to converge, we will remove the random intercept of toy_type: 

m_RT <- lmer(log(final_data$rt) ~ condition + condition*numCausal + condition*numFunctional + condition*numSymbol + condition*numBackground + (1|sketchID) + (1|gameID) + (totalStrokes|condition) + (totalStrokes|toy_type), data=final_data, REML=FALSE)
summary(m4)

Does condition influence accuracy 

m_corrAns <- glmer(final_data$corrAns ~ condition + condition*numCausal + condition*numFunctional + condition*numSymbol + condition*numBackground + (1|toy_type) + (1|sketchID) + (1|gameID) + (totalStrokes|condition) + (totalStrokes|toy_type), family="binomial", data=final_data)

If the model fails to converge, we will remove the random intercept of toy_type: 

m_corrAns <- glmer(final_data$corrAns ~ condition + condition*numCausal + condition*numFunctional + condition*numSymbol + condition*numBackground + (1|sketchID) + (1|gameID) + (totalStrokes|condition) + (totalStrokes|toy_type), family="binomial", data=final_data)

### Data exclusion
Sessions will be excluded from analysis based on the below exclusion criteria: 

Technical failure: Participants will complete an exit survey at the end of the experiment. If participants report that any of the sketches or images of machines did not display properly (e.g., images did not load or did not load at the same time) or if the interface did not function properly on a trial (e.g., participant could not click), all data from that session will be excluded from subsequent analysis. 

Failure to follow setup instructions: Before completing any test trials participants will be asked to make their browser window full screen to ensure that the participants’ browser window will have the entire stimuli in full view. If the dimensions of their browser window change throughout test trials, any test trials that have dimensions less than full screen will be excluded from subsequent analysis. Fullscreen will be determined by the dimensions of the first trial preceding immediately after participants are instructed to make their browser window fullscreen. 

Session-level accuracy-based exclusion: 

Absolute: To exclude sessions where responses seem to have been generated arbitrarily (i.e., by uniform guessing), we define two tiers of “chance-level” performance: (1) pure guessing between all six alternatives (16.7%); (2) pure guessing between the two variants of the same toy type (50%). Prior to data collection, we are uncertain about what mean accuracy will be, but insofar as there is any signal in these sketches at all to drive identification decisions, we expect it to exceed the 16.7% threshold. However, insofar as participants are guessing between the two variants within toy type, 50% might provide a better baseline for chance responding.

We plan to pilot our experiment with N=10 participants.

We estimate the mean accuracy for these participants. 

If sample mean +/- 1 standard error > 50%, then we’ll use the higher tier of chance-level responding. Under the higher tier, we will exclude sessions where fewer than 170 responses were correct (detecting ~99% of sessions under chance responding)

If sample mean +/- 1 standard error <= 50%, then we’ll use the lower tier of chance-level responding. Under the lower tier, we will exclude sessions where fewer than 60 trials were correct. 

Relative: All data from a session will be excluded if accuracy is less than 2.5 standard deviations below the mean (using mean & sd on N-1 sample excluding that session).

Trial-level response time outlier exclusions:

Absolute: To ensure that participants are making thoughtful decisions and not merely clicking through the task, trials will be excluded from subsequent analysis if the response time is less than 0.5 seconds. Trials will also be excluded from subsequent analysis if participants do not make a response in 10 seconds.  

Relative: Trials will be excluded if response times are greater than 2.5 standard deviations above the mean (using mean & sd on N-1 sample excluding that session).

We plan to release “raw” group dataframes containing all sessions and trials, but “flag” sessions and trials that meet our exclusion criteria to make it easy to filter these out during analysis. We further plan to apply the same analyses to both the raw & filtered datasets to evaluate the impact of our exclusion criteria on our conclusions. 

### Exploratory analysis
Within visual depictions, we predict sketches that contain elements with higher accuracy to spatial location, size, and shape of real-world elements will facilitate more accurate and faster identification of target objects.

## Other
### Other
References
[1] Sloman, S. (2005). Causal models: how people think about the world and its alternatives. Oxford University Press. 
<br>
[2] Meltzoff, A. (2007). Infants’ Causal Learning. Causal learning: psychology, philosophy, and computation, 37-47. Oxford University Press.
<br>
[3] Tversky, B., Agrawala, M., Heiser, J., Lee, P., Hanrahan, P., Phan, D., & Daniel, M. P. (2006). Cognitive design principles for automated generation of visualizations. In Allen G, editor. Applied Spatial Cognition: From Research to Cognitive Technology, 53-75. Hillsdale, NJ: Lawrence Erlbaum Associates, Inc.
<br>
[4] Larkin, J., & Simon, H. (1987). Why a diagram is (sometimes) worth ten thousand words. Cognitive Science: A Multidisciplinary Journal, 11, 65–100.
<br>
[5] Tversky, B., & Bobek, E. (2016). Creating visual explanations improves learning. Cognitive Research: Principles and Implications, 1(1), 27.
<br>
[6] Tversky, B., & Morrison, J. B. (2002). Animation: can it facilitate? International Journal of Human-Computer Studies, 57, 247-262.
<br>
[7] Tversky, B., & Heiser, J., (2006). Arrows in comprehending and producing mechanical diagrams. Cognitive Science, 30, 581-592.
<br>
[8] Tversky, B., Zacks, J., Lee, P., & Heiser, J. (2000). Lines, blobs, crosses and arrows: Diagrammatic communication with schematic figures. In International conference on theory and application of diagrams, 221-230. Springer, Berlin, Heidelberg.
